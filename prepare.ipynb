{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a86928b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b45ec0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Convert text to all lower case for normalcy.\n",
    "- Remove any accented characters, non-ASCII characters.\n",
    "- Remove special characters.\n",
    "- Stem or lemmatize the words.\n",
    "- Remove stopwords.\n",
    "- Store the clean text and the original text for use in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f753fccd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad9b68c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_science.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e663f66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns = 'link', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26582890",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company         0\n",
       "location        0\n",
       "mode            0\n",
       "type            0\n",
       "level           0\n",
       "role            0\n",
       "requirements    0\n",
       "edu_bachelor    0\n",
       "edu_master      0\n",
       "edu_phd         0\n",
       "edu_other       0\n",
       "skills          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4088918",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convert text to all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fb5bd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feef62a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bachelor degree\\nminimum years of experience: 4 year(s)\\ndemonstrates thorough abiliti...\n",
       "1      identify and execute on predictive models to help internal teams at masterworks unders...\n",
       "2      self-motivated, highly disciplined, and passionate about discovering the right therape...\n",
       "3      2 years + experience with python, java, or other object-oriented programming languages...\n",
       "4      2+ years of work experience doing quantitative analysis to tackle business problems\\ns...\n",
       "                                                 ...                                            \n",
       "195    3 to 5 years of experience in applied data science in a retail marketing or operations...\n",
       "196    bs in engineering, computer science, data science or equivalent\\n2+ years of experienc...\n",
       "197    4+ years of proven experience in an analytics role\\nability to communicate the results...\n",
       "198    3-7 years professional experience in data analysis or practical experience buildingâ€¯cu...\n",
       "199    develop and implement scalable and efficient models on large-scale datasets to address...\n",
       "Name: requirements, Length: 200, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7b47c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c59525b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    # Removing white space\n",
    "    string = re.sub(r'\\s+', ' ',   string)\n",
    "    # Removing anything that is not a-z, 0-9, a single quote, or whitespace\n",
    "    string = re.sub(r\"[^a-z0-9+'\\s]\", '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1066b5d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bdefb9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bachelor degree minimum years of experience 4 years demonstrates thorough abilities an...\n",
       "1      identify and execute on predictive models to help internal teams at masterworks unders...\n",
       "2      selfmotivated highly disciplined and passionate about discovering the right therapeuti...\n",
       "3      2 years + experience with python java or other objectoriented programming languages ha...\n",
       "4      2+ years of work experience doing quantitative analysis to tackle business problems st...\n",
       "                                                 ...                                            \n",
       "195    3 to 5 years of experience in applied data science in a retail marketing or operations...\n",
       "196    bs in engineering computer science data science or equivalent 2+ years of experience i...\n",
       "197    4+ years of proven experience in an analytics role ability to communicate the results ...\n",
       "198    37 years professional experience in data analysis or practical experience building cus...\n",
       "199    develop and implement scalable and efficient models on largescale datasets to address ...\n",
       "Name: requirements, Length: 200, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da63d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4b567c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f44b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f859b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44ce563",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "\n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359c71a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df4b67",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92584476",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stopwords_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3568eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf9300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}